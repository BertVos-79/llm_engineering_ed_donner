{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dfe37963-1af6-44fc-a841-8e462443f5e6",
   "metadata": {},
   "source": [
    "# RAG part 2\n",
    "\n",
    "## Load data and split into chunks with LangChain\n",
    "\n",
    "### Expert Knowledge Worker\n",
    "\n",
    "A question answering agent that is an expert knowledge worker\n",
    "To be used by employees of Insurellm, an Insurance Tech company\n",
    "The agent needs to be accurate and the solution should be low cost.\n",
    "\n",
    "This project will use RAG (Retrieval Augmented Generation) to ensure our question/answering assistant has high accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ba2779af-84ef-4227-9e9e-6eaf0df87e77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "\n",
    "import os\n",
    "import glob\n",
    "from dotenv import load_dotenv\n",
    "import gradio as gr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "802137aa-8a74-45e0-a487-d1974927d7ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports for langchain\n",
    "\n",
    "# Importing the 'DirectoryLoader' class from 'langchain.document_loaders' to load multiple documents \n",
    "#           from a specified directory, treating each file as a separate document.\n",
    "# Importing the 'TextLoader' class from 'langchain.document_loaders' to load a single text document \n",
    "#           from a specified file and process it as a single document.\n",
    "# Importing the 'CharacterTextSplitter' class from 'langchain.text_splitter' to split text \n",
    "#           documents into smaller chunks based on character-level criteria.\n",
    "\n",
    "\n",
    "from langchain.document_loaders import DirectoryLoader, TextLoader\n",
    "from langchain.text_splitter import CharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ee78efcb-60fe-449e-a944-40bab26261af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load environment variables in a file called .env\n",
    "\n",
    "load_dotenv()\n",
    "os.environ['OPENAI_API_KEY'] = os.getenv('OPENAI_API_KEY', 'your-key-if-not-using-env')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7f90427-d660-4ac2-a6cb-3bb71dffc7b1",
   "metadata": {},
   "source": [
    "## 1. Load Data with LangChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "730711a9-6ffe-4eee-8f48-d6cfb7314905",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The DirectoryLoader reads all markdown files (*.md) from the knowledge-base folder and its subfolders\n",
    "\n",
    "# Using 'glob.glob' to find all subdirectories in the \"knowledge-base/\" directory.\n",
    "# Initializing an empty list 'documents' to store all loaded documents with metadata.\n",
    "# Iterating through each folder found in the \"knowledge-base/\" directory.\n",
    "# Extracting the folder name (base name) from its complete path to use as the document type.\n",
    "# The DirectoryLoader class scans a specified folder (and optionally its subdirectories) \n",
    "# to find files that match specific criteria.\n",
    "# - glob: Specifies the pattern of files to load. \n",
    "#   For example, \"**/*.md\" means it will recursively search for all Markdown files (.md) \n",
    "#   in the directory and its subdirectories.\n",
    "# - loader_cls: Specifies the loader class to use for processing each file. \n",
    "#   In this case, TextLoader is used. TextLoader reads the content of each file and\n",
    "#   converts it into a Document object.\n",
    "# DirectoryLoader only defines the configuration and does not automatically load the files; \n",
    "# the load() method is required to execute the loading process in the current folder according to the set configuration\n",
    "# Iterating over each loaded file of the Document type to set its attribute metadata \n",
    "# to its document type (derived from the folder name).\n",
    "# Appending each processed document with metadata to the 'documents' list.\n",
    "\n",
    "\n",
    "folders = glob.glob(\"knowledge-base/*\")\n",
    "\n",
    "documents = []\n",
    "for folder in folders:\n",
    "    doc_type = os.path.basename(folder)\n",
    "    loader = DirectoryLoader(folder, glob=\"**/*.md\", loader_cls=TextLoader)\n",
    "    folder_docs = loader.load()\n",
    "    for doc in folder_docs:\n",
    "        doc.metadata[\"doc_type\"] = doc_type\n",
    "        documents.append(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "252f17e9-3529-4e81-996c-cfa9f08e75a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7e8decb0-d9b0-4d51-8402-7a6174d22159",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(metadata={'source': 'knowledge-base/employees/Maxine Thompson.md', 'doc_type': 'employees'}, page_content=\"# HR Record\\n\\n# Maxine Thompson\\n\\n## Summary\\n- **Date of Birth:** January 15, 1991  \\n- **Job Title:** Data Engineer  \\n- **Location:** Austin, Texas  \\n\\n## Insurellm Career Progression\\n- **January 2017 - October 2018**: **Junior Data Engineer**  \\n  * Maxine joined Insurellm as a Junior Data Engineer, focusing primarily on ETL processes and data integration tasks. She quickly learned Insurellm's data architecture, collaborating with other team members to streamline data workflows.  \\n- **November 2018 - December 2020**: **Data Engineer**  \\n  * In her new role, Maxine expanded her responsibilities to include designing comprehensive data models and improving data quality measures. Though she excelled in technical skills, communication issues with non-technical teams led to some project delays.  \\n- **January 2021 - Present**: **Senior Data Engineer**  \\n  * Maxine was promoted to Senior Data Engineer after successfully leading a pivotal project that improved data retrieval times by 30%. She now mentors junior engineers and is involved in strategic data initiatives, solidifying her position as a valued asset at Insurellm. She was recognized as Insurellm Innovator of the year in 2023, receiving the prestigious IIOTY 2023 award.  \\n\\n## Annual Performance History\\n- **2017**: *Meets Expectations*  \\n  Maxine showed potential in her role but struggled with initial project deadlines. Her adaptability and willingness to learn made positive impacts on her team.  \\n\\n- **2018**: *Exceeds Expectations*  \\n  Maxine improved significantly, becoming a reliable team member with strong problem-solving skills. She took on leadership in a project that automated data entry processes.  \\n\\n- **2019**: *Needs Improvement*  \\n  During this year, difficult personal circumstances affected Maxine's performance. She missed key deadlines and had several communication issues with stakeholders.  \\n\\n- **2020**: *Meets Expectations*  \\n  Maxine focused on regaining her footing and excelling with technical skills. She was stable, though not standout, in her contributions. Feedback indicated a need for more proactivity.  \\n\\n- **2021**: *Exceeds Expectations*  \\n  Maxine spearheaded the transition to a new data warehousing solution, significantly enhancing Insurellm’s data analytics capabilities. This major achievement bolstered her reputation within the company.  \\n\\n- **2022**: *Outstanding*  \\n  Maxine continued her upward trajectory, successfully implementing machine learning algorithms to predict customer behavior, which was well-received by the leadership team and improved client satisfaction.  \\n\\n- **2023**: *Exceeds Expectations*  \\n  Maxine has taken on mentoring responsibilities and is leading a cross-functional team for data governance initiatives, showcasing her leadership and solidifying her role at Insurellm.  \\n\\n## Compensation History\\n- **2017**: $70,000 (Junior Data Engineer)  \\n- **2018**: $75,000 (Junior Data Engineer)  \\n- **2019**: $80,000 (Data Engineer)  \\n- **2020**: $84,000 (Data Engineer)  \\n- **2021**: $95,000 (Senior Data Engineer)  \\n- **2022**: $110,000 (Senior Data Engineer)  \\n- **2023**: $120,000 (Senior Data Engineer)  \\n\\n## Other HR Notes\\n- Maxine participated in various company-sponsored trainings related to big data technologies and cloud infrastructure.  \\n- She was recognized for her contributions with the “Insurellm Innovator Award” in 2022.  \\n- Maxine is currently involved in the women-in-tech initiative and participates in mentorship programs to guide junior employees.  \\n- Future development areas include improving her stakeholder communication skills to ensure smoother project transitions and collaboration.  \")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents[24]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34ed2b78-31ee-43df-b891-75b71e0ad7fd",
   "metadata": {},
   "source": [
    "## 2. Split Documents into Chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7310c9c8-03c1-4efc-a104-5e89aec6db1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Created a chunk of size 1088, which is longer than the specified 1000\n"
     ]
    }
   ],
   "source": [
    "# Creating an instance of 'CharacterTextSplitter' to divide documents into smaller, overlapping chunks.\n",
    "# Setting the 'chunk_size' to 1000, meaning each chunk will contain up to 1000 characters.\n",
    "# Setting the 'chunk_overlap' to 200, so there will be a 200-character overlap between consecutive chunks.\n",
    "# Using the '.split_documents()' method from the 'CharacterTextSplitter' object to split\n",
    "# the list of documents ('documents') into smaller chunks.\n",
    "# A chunk is an instance of the LangChain Document class that has attributes .metadata and .pagecontent,\n",
    "# which allows to search both type and the content of the processed documents\n",
    "# The resulting 'chunks' list contains all the split chunks of the documents.\n",
    "\n",
    "text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "chunks = text_splitter.split_documents(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cd06e02f-6d9b-44cc-a43d-e1faa8acc7bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "123"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check length of the list of chunks\n",
    "\n",
    "len(chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d2562754-9052-4aae-92c1-37236435ea06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(metadata={'source': 'knowledge-base/products/Markellm.md', 'doc_type': 'products'}, page_content='- **User-Friendly Interface**: Designed with user experience in mind, Markellm features an intuitive interface that allows consumers to easily browse and compare various insurance offerings from multiple providers.\\n\\n- **Real-Time Quotes**: Consumers can receive real-time quotes from different insurance companies, empowering them to make informed decisions quickly without endless back-and-forth communication.\\n\\n- **Customized Recommendations**: Based on user profiles and preferences, Markellm provides personalized insurance recommendations, ensuring consumers find the right coverage at competitive rates.\\n\\n- **Secure Transactions**: Markellm prioritizes security, employing robust encryption methods to ensure that all transactions and data exchanges are safe and secure.\\n\\n- **Customer Support**: Our dedicated support team is always available to assist both consumers and insurers throughout the process, providing guidance and answering any questions that may arise.')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check content of chunk at index 6 of list of chunks\n",
    "\n",
    "chunks[6]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de8b51b4-f094-49ac-907d-29c875b35833",
   "metadata": {},
   "source": [
    "### How Chunks are Split in `CharacterTextSplitter`\n",
    "\n",
    "CharacterTextSplitter prioritizes mechanical splitting by size and overlap, optionally respecting basic boundaries (like sentences). Meaning does not play a role.\n",
    "\n",
    "The `CharacterTextSplitter` splits documents into smaller chunks based on the following criteria:\n",
    "\n",
    "#### 1. **Character Count (`chunk_size`)**\n",
    "- Each chunk will contain a maximum number of characters specified by the `chunk_size` parameter.\n",
    "- For example, if `chunk_size=1000`, each chunk will include up to 1000 characters.\n",
    "\n",
    "#### 2. **Overlap (`chunk_overlap`)**\n",
    "- Consecutive chunks will overlap by the number of characters specified in the `chunk_overlap` parameter.\n",
    "- For instance, with `chunk_overlap=200`, the last 200 characters of one chunk will also appear at the beginning of the next chunk.\n",
    "- This overlap ensures context continuity between chunks, which is particularly important for tasks such as Natural Language Processing (NLP).\n",
    "\n",
    "#### 3. **Natural Boundaries**\n",
    "- The `CharacterTextSplitter` attempts to split chunks at logical boundaries, such as:\n",
    "  - End of sentences\n",
    "  - Paragraph breaks\n",
    "- This prevents splitting words or sentences in an awkward manner. If natural boundaries are not specified, the splitting is purely character-based.\n",
    "\n",
    "#### Example\n",
    "Given the following text:\n",
    "\n",
    "```\n",
    "This is a simple example document. It explains the splitting process in detail. Each chunk has up to 50 characters with overlaps of 20 for context.\n",
    "```\n",
    "\n",
    "With `chunk_size=50` and `chunk_overlap=20`, the resulting chunks might look like this:\n",
    "- **Chunk 1:** `\"This is a simple example document. It explains the\"`\n",
    "- **Chunk 2:** `\"example document. It explains the splitting process\"`\n",
    "- **Chunk 3:** `\"the splitting process in detail. Each chunk has\"`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2c54b4b6-06da-463d-bee7-4dd456c2b887",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document types found: products, contracts, company, employees\n"
     ]
    }
   ],
   "source": [
    "# Use the atrribute .metadata of chunk (= instance of Document Class)\n",
    "\n",
    "doc_types = set(chunk.metadata['doc_type'] for chunk in chunks)\n",
    "print(f\"Document types found: {', '.join(doc_types)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "128c73f7-f149-4904-a554-8140941fce0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page_content='## Support\n",
      "\n",
      "1. **Customer Support**: Velocity Auto Solutions will have access to Insurellm’s customer support team via email or chatbot, available 24/7.  \n",
      "2. **Technical Maintenance**: Regular maintenance and updates to the Carllm platform will be conducted by Insurellm, with any downtime communicated in advance.  \n",
      "3. **Training & Resources**: Initial training sessions will be provided for Velocity Auto Solutions’ staff to ensure effective use of the Carllm suite. Regular resources and documentation will be made available online.\n",
      "\n",
      "---\n",
      "\n",
      "**Accepted and Agreed:**  \n",
      "**For Velocity Auto Solutions**  \n",
      "Signature: _____________________  \n",
      "Name: John Doe  \n",
      "Title: CEO  \n",
      "Date: _____________________  \n",
      "\n",
      "**For Insurellm**  \n",
      "Signature: _____________________  \n",
      "Name: Jane Smith  \n",
      "Title: VP of Sales  \n",
      "Date: _____________________' metadata={'source': 'knowledge-base/contracts/Contract with Velocity Auto Solutions for Carllm.md', 'doc_type': 'contracts'}\n",
      "_________\n",
      "page_content='3. **Regular Updates:** Insurellm will offer ongoing updates and enhancements to the Homellm platform, including new features and security improvements.\n",
      "\n",
      "4. **Feedback Implementation:** Insurellm will actively solicit feedback from GreenValley Insurance to ensure Homellm continues to meet their evolving needs.\n",
      "\n",
      "---\n",
      "\n",
      "**Signatures:**\n",
      "\n",
      "_________________________________  \n",
      "**[Name]**  \n",
      "**Title**: CEO  \n",
      "**Insurellm, Inc.**\n",
      "\n",
      "_________________________________  \n",
      "**[Name]**  \n",
      "**Title**: COO  \n",
      "**GreenValley Insurance, LLC**  \n",
      "\n",
      "---\n",
      "\n",
      "This agreement represents the complete understanding of both parties regarding the use of the Homellm product and supersedes any prior agreements or communications.' metadata={'source': 'knowledge-base/contracts/Contract with GreenValley Insurance for Homellm.md', 'doc_type': 'contracts'}\n",
      "_________\n",
      "page_content='# Avery Lancaster\n",
      "\n",
      "## Summary\n",
      "- **Date of Birth**: March 15, 1985  \n",
      "- **Job Title**: Co-Founder & Chief Executive Officer (CEO)  \n",
      "- **Location**: San Francisco, California  \n",
      "\n",
      "## Insurellm Career Progression\n",
      "- **2015 - Present**: Co-Founder & CEO  \n",
      "  Avery Lancaster co-founded Insurellm in 2015 and has since guided the company to its current position as a leading Insurance Tech provider. Avery is known for her innovative leadership strategies and risk management expertise that have catapulted the company into the mainstream insurance market.  \n",
      "\n",
      "- **2013 - 2015**: Senior Product Manager at Innovate Insurance Solutions  \n",
      "  Before launching Insurellm, Avery was a leading Senior Product Manager at Innovate Insurance Solutions, where she developed groundbreaking insurance products aimed at the tech sector.' metadata={'source': 'knowledge-base/employees/Avery Lancaster.md', 'doc_type': 'employees'}\n",
      "_________\n"
     ]
    }
   ],
   "source": [
    "# Use the atrribute .page_content of chunk (= instance of Document Class)\n",
    "\n",
    "for chunk in chunks:\n",
    "    if 'CEO' in chunk.page_content:\n",
    "        print(chunk)\n",
    "        print(\"_________\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6965971c-fb97-482c-a497-4e81a0ac83df",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
