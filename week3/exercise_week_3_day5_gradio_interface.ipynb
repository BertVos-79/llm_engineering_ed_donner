{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2WPLBXFHeus5"
   },
   "source": [
    "![Meeting Minutes Cover](https://media.licdn.com/dms/image/D4D12AQHDwTFupp2TTA/article-cover_image-shrink_720_1280/0/1701168770707?e=2147483647&v=beta&t=iPZMm8gUXWO3NvMRaoxNTFkvEYVXP3SyHLtNpw41nw8)\n",
    "\n",
    "\n",
    "# Audio to Meeting Minutes Tool\n",
    "\n",
    "## Functionality\n",
    "\n",
    "This tool automates the process of generating professional meeting minutes from audio recordings. It takes an audio file stored on Google Drive as input, transcribes it into text using OpenAI's Whisper model, and summarizes the transcription into structured meeting minutes. The meeting minutes include:\n",
    "\n",
    "- **Summary**: Key details such as attendees, location, and date.\n",
    "- **Discussion Points**: Highlights of the conversations.\n",
    "- **Takeaways**: Key insights and conclusions.\n",
    "- **Action Items**: Specific tasks with assigned owners.\n",
    "\n",
    "The output is provided in a markdown format, making it easy to view, edit, or save in various formats.\n",
    "\n",
    "## How It Functions\n",
    "\n",
    "1. **Input**: The user specifies the Google Drive path to the audio file and provides API credentials for OpenAI and Hugging Face.\n",
    "2. **Transcription**: The tool processes the audio file and converts it to text using OpenAI's Whisper model.\n",
    "3. **Summarization**: A pre-trained language model (LLAMA) generates meeting minutes based on the transcription.\n",
    "4. **Output**: The summarized minutes are displayed and can be downloaded in markdown format.\n",
    "\n",
    "## Why It Can Be Useful\n",
    "\n",
    "This tool is highly beneficial for:\n",
    "- **Efficiency**: Automating the labor-intensive task of manually transcribing and summarizing meeting audio.\n",
    "- **Consistency**: Producing well-structured and professional meeting minutes.\n",
    "- **Accessibility**: Saving minutes in markdown ensures compatibility with various text-processing tools.\n",
    "- **Collaboration**: Simplifying sharing and editing of meeting records among team members.\n",
    "\n",
    "By leveraging state-of-the-art models, this tool ensures accurate transcription and coherent summarization, making it an invaluable asset for professionals handling frequent meetings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 663
    },
    "executionInfo": {
     "elapsed": 20273,
     "status": "ok",
     "timestamp": 1733848536660,
     "user": {
      "displayName": "Bert Vos",
      "userId": "06544227375617021316"
     },
     "user_tz": -60
    },
    "id": "ydfYuAnZaaxS",
    "outputId": "0ab9eedc-a645-429a-ce1d-382886f3484b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n",
      "Running Gradio in a Colab notebook requires sharing enabled. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
      "\n",
      "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
      "* Running on public URL: https://d390306ff0795fcd41.gradio.live\n",
      "\n",
      "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://d390306ff0795fcd41.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "!pip install -q gradio fpdf python-docx requests torch bitsandbytes transformers sentencepiece accelerate openai httpx==0.27.2\n",
    "\n",
    "import gradio as gr\n",
    "import os\n",
    "from google.colab import drive\n",
    "from huggingface_hub import login\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, TextStreamer, BitsAndBytesConfig\n",
    "import torch\n",
    "from openai import OpenAI\n",
    "from IPython.display import Markdown\n",
    "from fpdf import FPDF\n",
    "from docx import Document\n",
    "from time import sleep\n",
    "\n",
    "# Constants\n",
    "AUDIO_MODEL = \"whisper-1\"\n",
    "LLAMA = \"meta-llama/Meta-Llama-3.1-8B-Instruct\"\n",
    "\n",
    "# Mount Google Drive\n",
    "drive.mount(\"/content/drive\")\n",
    "\n",
    "def save_to_file(content, format):\n",
    "    file_path = f\"meeting_minutes.{format}\"\n",
    "    if format == \"txt\":\n",
    "        with open(file_path, \"w\") as file:\n",
    "            file.write(content)\n",
    "    elif format == \"pdf\":\n",
    "        pdf = FPDF()\n",
    "        pdf.add_page()\n",
    "        pdf.set_font(\"Arial\", size=12)\n",
    "        for line in content.splitlines():\n",
    "            pdf.cell(0, 10, line, ln=True)\n",
    "        pdf.output(file_path)\n",
    "    elif format == \"docx\":\n",
    "        doc = Document()\n",
    "        doc.add_paragraph(content)\n",
    "        doc.save(file_path)\n",
    "    return file_path\n",
    "\n",
    "def transcribe_and_summarize(audio_path, hf_token, openai_api_key, output_format, progress=gr.Progress()):\n",
    "    try:\n",
    "        # Initialize APIs\n",
    "        login(hf_token, add_to_git_credential=True)\n",
    "        openai = OpenAI(api_key=openai_api_key)\n",
    "\n",
    "        # Step 1: Transcribe audio using OpenAI Whisper\n",
    "        progress(10, \"Starting transcription...\")\n",
    "        audio_file = open(audio_path, \"rb\")\n",
    "        transcription = openai.audio.transcriptions.create(\n",
    "            model=AUDIO_MODEL, file=audio_file, response_format=\"text\"\n",
    "        )\n",
    "        progress(50, \"Transcription complete. Generating meeting minutes...\")\n",
    "\n",
    "        # Step 2: Prepare LLM prompt\n",
    "        system_message = \"You are an assistant that produces minutes of meetings from transcripts, with summary, key discussion points, takeaways and action items with owners, in markdown.\"\n",
    "        user_prompt = (\n",
    "            f\"Below is an extract transcript of a Denver council meeting. Please write minutes in markdown, including a summary with attendees, location and date; discussion points; takeaways; and action items with owners.\\n{transcription}\"\n",
    "        )\n",
    "\n",
    "        messages = [\n",
    "            {\"role\": \"system\", \"content\": system_message},\n",
    "            {\"role\": \"user\", \"content\": user_prompt},\n",
    "        ]\n",
    "\n",
    "        # Step 3: Load model and tokenizer\n",
    "        quant_config = BitsAndBytesConfig(\n",
    "            load_in_4bit=True,\n",
    "            bnb_4bit_use_double_quant=True,\n",
    "            bnb_4bit_compute_dtype=torch.bfloat16,\n",
    "            bnb_4bit_quant_type=\"nf4\",\n",
    "        )\n",
    "\n",
    "        tokenizer = AutoTokenizer.from_pretrained(LLAMA)\n",
    "        tokenizer.pad_token = tokenizer.eos_token\n",
    "        inputs = tokenizer.apply_chat_template(messages, return_tensors=\"pt\").to(\"cuda\")\n",
    "        streamer = TextStreamer(tokenizer)\n",
    "\n",
    "        model = AutoModelForCausalLM.from_pretrained(\n",
    "            LLAMA, device_map=\"auto\", quantization_config=quant_config\n",
    "        )\n",
    "\n",
    "        # Step 4: Generate outputs\n",
    "        outputs = model.generate(inputs, max_new_tokens=2000, streamer=streamer)\n",
    "        progress(90, \"Meeting minutes generation nearly complete...\")\n",
    "\n",
    "        # Decode response\n",
    "        response = tokenizer.decode(outputs[0])\n",
    "\n",
    "        # Save to file\n",
    "        file_path = save_to_file(response, output_format)\n",
    "        progress(100, \"Meeting minutes generation complete.\")\n",
    "\n",
    "        return response, file_path\n",
    "\n",
    "    except Exception as e:\n",
    "        return f\"An error occurred: {str(e)}\", None\n",
    "\n",
    "# Gradio Interface\n",
    "def interface():\n",
    "    with gr.Blocks() as demo:\n",
    "        gr.Markdown(\"### Audio to Meeting Minutes\")\n",
    "\n",
    "        audio_path = gr.Textbox(label=\"Google Drive Path for Audio\")\n",
    "        hf_token = gr.Textbox(label=\"Hugging Face Token\", type=\"password\")\n",
    "        openai_api_key = gr.Textbox(label=\"OpenAI API Key\", type=\"password\")\n",
    "        output_format = gr.Radio([\"txt\", \"pdf\", \"docx\"], label=\"Output Format\", value=\"txt\")\n",
    "\n",
    "        output_text = gr.Markdown()\n",
    "        output_file = gr.File(label=\"Download Meeting Minutes\")\n",
    "\n",
    "        transcribe_button = gr.Button(\"Generate Minutes\")\n",
    "\n",
    "        transcribe_button.click(\n",
    "            transcribe_and_summarize,\n",
    "            inputs=[audio_path, hf_token, openai_api_key, output_format],\n",
    "            outputs=[output_text, output_file],\n",
    "            show_progress=True\n",
    "        )\n",
    "\n",
    "    return demo\n",
    "\n",
    "# Launch the interface\n",
    "demo = interface()\n",
    "demo.launch()\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyN68DoY9QiEyxhrJ+bjOf1R",
   "gpuType": "L4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
